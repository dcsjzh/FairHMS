# Fair Happiness Maximizing Sets - FairHMS

This repository contains source codes in our paper "Happiness Maximizing Sets under Group Fairness Constraints" which introduces a 2-dimensional exact algorithm (INTCOV) and two multi-dimensional bicriteria approximation algorithms (BIGREEDY and BIGREEDY+) for the fair happiness maximization set (FairHMS) problem. In our experiments, we implemented our proposed algorithms in C++. In addition all baseline algorithms we evaluated in our experiments are also available online. Please refer to https://users.cs.duke.edu/~ssintos/kRMS_SEA/ for the implementation of eps-Kernel, Greedy, and HittingSet(HS); and https://www.cse.ust.hk/~raywong/code/sigmod18-sphere.zip for the implementation of DMM and Sphere.

## Datasets
This repository also provides two processed dataset used in our experiments, as follows:

The synthetic dataset includes: 
* anti_2_10000_skyline is 2d dataset with 10,000 tuples and is divided into 3 equal-sized groups. The synthetic datasets used in our experiments are generated by the generator [S. Börzsönyi, D. Kossmann, and K. Stocker. The skyline operator. In ICDE, pages 421--430, 2001. DOI: 10.1109/ICDE.2001.914855]

The real dataset is:
* The Adult dataset is a 5d dataset with 32,561 tuples, each of which contains an individual's education years, capital gain, capital lose, work hours per week and overall weight. The dataset is divided into groups by gender and race. Available: https://archive.ics.uci.edu/ml/datasets/adult

If you need other datasets used in our paper, feel free to contact .

## How to reproduce the experiments in our paper

### Preconditions

If you are interested in re-running the experiments in our paper, please ensure that the following libraries are configured correctly in your system.

1. gurobi library. (https://www.gurobi.com/)
2. ann library. (https://cs.umd.edu/~mount/ANN)
3. glpk library. (https://www.gnu.org/software/glpk/)

### Usage

First clone this repository:

	git clone https://github.com/dcsjzh/FairHMS.git

Then you should end up with the following files:

- `data/`: contains two processed datasets as introduced above after attribute normalization and skyline computation. `adultSky.txt` stands for the `Adult` dataset where the dimensionality is 5, the dataset size is 32,561, and the number of the groups is 2. `anti_2_10000_skyline.txt` stands for the `Anti-Correlated` dataset where the dimensionality is 2, the dataset size is 10,000, and the number of the groups is 3.

- `executable/`: Contains the executable file after the compilation process.

- `result/`: Is used to store results that algorithms output.

- `utils/`: Contains our utility functions sampled under different dimensions.

- `src/`: Contains the `C++` implementation of all algorithms.

Assuming that you followed the instructions above, in order to run the algorithms, you need to execute the following steps:

a. Compilation
	cd src
	make

b. Execution
	cd ../executable

Follow the command format below, you could run all algorithms with a specific number of categories, a specific k on the dataset and a 2D dataset flag is2D.
	./run.out dataset NumberofCategories k is2D 

e.g., for high-dimensional dataset:
	./run.out anti_6_100_skyline.txt 1 10 0

e.g., for two-dimensional dataset:
	./run.out anti_2_100_skyline.txt 1 5 1
	
c. Output
	The output will be stored in the folder `result`.







